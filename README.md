# ELGC
FACE EXPRESSIONS Detection
They have difficulty in recognizing people’s face expressions and giving 
expressions. Therefore, they are unable to interact in society through non-verbal 
communication. The system will maintain a dynamic source of picture and after applying 
image processing techniques it will generate the models to classify them into different 
moods. Moreover, research will be performed to define a mood for detecting autism in 
patients. There will also be criteria set to get information about extent to which the 
expression recognition skills have been developed in the users.


 First, the app will start and ask user to capture or browse image.
 Then app will convert an RGB image to greyscale/Bitmap and apply noise 
reduction techniques.
 After that, app will detect image and extract required features to create facial 
expressions.
 Then using mood classifiers, it will generate a model.
 After that generated model will be matched to trained data using cognitive 
analysis.
 If model matches then app will generate an alert about mood detection.
 At last, detected mood will be tested
